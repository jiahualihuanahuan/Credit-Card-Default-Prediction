{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose:\n",
    "Predict if a person will default their credit card next month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('D:/Dropbox/GitHub/Credit Card Default Prediction/UCI_Credit_Card.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename two columns\n",
    "df=df.rename(columns={'default.payment.next.month':'def_pay','PAY_0':'PAY_1'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dealing with categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SEX: replace 1 with male and 2 with female\n",
    "df['SEX'] = df['SEX'].replace(1,'male').replace(2,'female')\n",
    "# EDUCATION: \n",
    "df['EDUCATION'] = df['EDUCATION'].replace(0,5).replace(6,5).replace(1,'graduate school').replace(2,'university').replace(3,'high school').replace(4,'others').replace(5,'unknown')\n",
    "# MARRIAGE\n",
    "df['MARRIAGE'] = df['MARRIAGE'].replace(0,3).replace(1,'married').replace(2,'single').replace(3,'others')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2212"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate default rate\n",
    "df.def_pay.sum()/len(df.def_pay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare X and y for machine learning\n",
    "X = df.drop(['def_pay','ID'],axis=1)\n",
    "y=df['def_pay'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into training and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transofrmation pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# determine categorical and numerical features\n",
    "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_cols = X.select_dtypes(include=['object', 'bool']).columns\n",
    "\n",
    "\n",
    "# Preprocessing for numerical data\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('standardize', StandardScaler())])\n",
    "\n",
    "# Preprocessing for categorical data\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "\n",
    "# Bundle preprocessing for numerical and categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1000 candidates, totalling 5000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=-1)]: Done 200 tasks      | elapsed:   11.9s\n",
      "[Parallel(n_jobs=-1)]: Done 572 tasks      | elapsed:   24.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1008 tasks      | elapsed:   42.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1667 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 2448 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 3186 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 4520 tasks      | elapsed:  3.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Decision Tree Parameters: {'tol': 1000.0, 'solver': 'lbfgs', 'C': 177827941.00389227}\n",
      "Best score is 0.40835104624954505\n",
      "random search cross validation results saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 5000 out of 5000 | elapsed:  3.6min finished\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "param_dist={\n",
    "    'solver':['lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "    'C':np.logspace(-9, 9, num=50, base=10),\n",
    "    'tol':np.logspace(-9, 9, num=50, base=10)\n",
    "}\n",
    "\n",
    "lr_cv = RandomizedSearchCV(LogisticRegression(),param_dist,cv=5,scoring='f1',verbose=1, n_jobs=-1, n_iter=1000)\n",
    "\n",
    "# Bundle preprocessing and modeling code in a pipeline\n",
    "my_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                              ('random_search', lr_cv)\n",
    "                             ])\n",
    "\n",
    "my_pipeline.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Print the tuned parameters and score\n",
    "print(\"Tuned Decision Tree Parameters: {}\".format(lr_cv.best_params_))\n",
    "print(\"Best score is {}\".format(lr_cv.best_score_))\n",
    "\n",
    "# save grid search cross validation results to file\n",
    "results = pd.DataFrame(lr_cv.cv_results_)\n",
    "results.to_csv('credit default logistic regression random search result.csv',index=False)\n",
    "print('random search cross validation results saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set model accuracy =  0.7972857142857143\n",
      "training set model f1 score =  0.2434689888039808\n",
      "testing set model accuracy =  0.7972222222222223\n",
      "testing set model f1 score =  0.2302825811893716\n",
      "testing set model classification report : \n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.98      0.88      7040\n",
      "           1       0.66      0.14      0.23      1960\n",
      "\n",
      "    accuracy                           0.80      9000\n",
      "   macro avg       0.73      0.56      0.56      9000\n",
      "weighted avg       0.77      0.80      0.74      9000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use the best hyper parameters to build the model\n",
    "logistic_regression_clf = lr_cv.best_estimator_\n",
    "\n",
    "# Bundle preprocessing and modeling code in a pipeline\n",
    "my_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                              ('clf', logistic_regression_clf)\n",
    "                             ])\n",
    "\n",
    "# Preprocessing of training data, fit model \n",
    "my_pipeline.fit(X_train, y_train)\n",
    "y_train_pred = my_pipeline.predict(X_train)\n",
    "y_pred = my_pipeline.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('training set model accuracy = ', accuracy_score(y_train, y_train_pred))\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "print('training set model f1 score = ', f1_score(y_train, y_train_pred))\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('testing set model accuracy = ', accuracy_score(y_test, y_pred))\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "print('testing set model f1 score = ', f1_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print('testing set model classification report : \\n ', classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
